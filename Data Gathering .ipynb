{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used this note to gather data from Souq.com.sa Daily deal \n",
    "used Selenium with chrome driver to navigate the website and use script to scroll down the page and download it for later retrive it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create browser object\n",
    "driver = webdriver.Chrome('chromedriver/chromedriver')\n",
    "# request the url\n",
    "driver.get(\"https://deals.souq.com/sa-en/?utm_source=souq&q=eyJzIjoiYmVzdCIsImYiOnsiaWRfdHlwZV9pdGVtIjpbIjQ2NyJdfX0%3D\")\n",
    "#to scroll down the page\n",
    "################ SCRIPT #########\n",
    "#driver.execute_script(\"window.scrollTo(0,1000000)\")\n",
    "SCROLL_PAUSE_TIME = 0.5\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height < last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "#give it some time \n",
    "sleep(5)\n",
    "# retrive, download page\n",
    "html = driver.page_source\n",
    "#close\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_lst = soup.find_all('div', attrs={'class' : 'columns small-8 medium-12'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Browsing the first item\n",
    "#item_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naming the lists\n",
    "item_name = []\n",
    "item_price = []\n",
    "item_category = []\n",
    "item_after_discount = []\n",
    "percentage_solds = []\n",
    "money_saving = []\n",
    "item_shipping = []\n",
    "item_rating = []\n",
    "item_category = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loop to retrive all the data and append it on the lists\n",
    "for item in item_lst:\n",
    "    item_category.append('Sportswear')\n",
    "    item_name.append((item.find('span', attrs={'class': 'itemTitle'}).text.strip()))\n",
    "    item_price.append(''.join(item.find('span', attrs={'class': 'is block sk-clr1'}).text.split()))\n",
    "    percentage_solds.append(re.search(r'\\d+', item.find('small', attrs={'class': 'progress-state sk-clr1'}).text.strip()).group())\n",
    "    item_shipping.append((item.find('div', attrs={'class': 'free-shipping'}).text.strip()))\n",
    "    try:\n",
    "        item_after_discount.append(''.join(item.find('span', attrs={'class': 'was block'}).text.split()))\n",
    "    except:\n",
    "        item_after_discount.append(np.nan)\n",
    "    try:\n",
    "        item_rating.append(re.search(r'\\d+', item.find('i', {'class':'star-rating-svg'}).find('i')['style']).group())    \n",
    "    except:\n",
    "        item_rating.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataframe\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the lists of array to the dataFrame\n",
    "df['item_category'] = item_category\n",
    "df['item_name'] = item_name\n",
    "df['item_after_discount'] = item_after_discount\n",
    "df['item_price'] = item_price\n",
    "df['percentage_solds'] = percentage_solds\n",
    "df['item_rating'] = item_rating\n",
    "df['item_shipping'] = item_shipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the data frame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new list and asign it with the value None\n",
    "df['buyer_gender'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loop to cheack the item_name description and look for the gender and asign it to the Buyer_gender\n",
    "for gender in ['men', 'women', 'Unisex']:\n",
    "    df['buyer_gender'][df['item_name'].str.contains(gender, flags=re.IGNORECASE, regex=True)] = gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the empty value with nan\n",
    "df.item_shipping.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.percentage_solds.replace('0', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving each Dataset and read it \n",
    "df.to_csv('./datasets/Sportswear.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sportswear_df = pd.read_csv('./datasets/Sportswear.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sportswear_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
